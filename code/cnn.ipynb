{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b_lAjylghmA3",
   "metadata": {
    "id": "b_lAjylghmA3"
   },
   "outputs": [],
   "source": [
    "import torch \n",
    "from torch import nn\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, Subset\n",
    "from tqdm import tqdm\n",
    "import h5py\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c49d1bdc",
   "metadata": {
    "id": "c49d1bdc"
   },
   "outputs": [],
   "source": [
    "gamma_f= h5py.File(\"piplus.hdf5\", 'r') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ODfrU8PhdYaQ",
   "metadata": {
    "id": "ODfrU8PhdYaQ"
   },
   "outputs": [],
   "source": [
    "energy = gamma_f['energy'][:]\n",
    "layer_0 = gamma_f['layer_0'][:]\n",
    "layer_1 = gamma_f['layer_1'][:]\n",
    "layer_2 = gamma_f['layer_2'][:]\n",
    "overflow = gamma_f['overflow'][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9acb809",
   "metadata": {
    "id": "b9acb809"
   },
   "outputs": [],
   "source": [
    "eplus_f = h5py.File(\"eplus.hdf5\", 'r') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03a8b69e",
   "metadata": {
    "id": "03a8b69e"
   },
   "outputs": [],
   "source": [
    "energy_ep = eplus_f['energy'][:]\n",
    "layer_0_ep = eplus_f['layer_0'][:]\n",
    "layer_1_ep = eplus_f['layer_1'][:]\n",
    "layer_2_ep = eplus_f['layer_2'][:]\n",
    "overflow_ep = eplus_f['overflow'][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "Zc7LO08Yn15q",
   "metadata": {
    "id": "Zc7LO08Yn15q"
   },
   "outputs": [],
   "source": [
    "trans = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    # transforms.CenterCrop(6),\n",
    "    transforms.Normalize((0.0), (1.0)),]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "4966a031",
   "metadata": {
    "id": "4966a031"
   },
   "outputs": [],
   "source": [
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, labels, layer_0, layer_1,layer_02):\n",
    "        self.labels = labels\n",
    "        self.layer_0 = layer_0 \n",
    "        self.layer_1 = layer_1\n",
    "        self.layer_2 = layer_2\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image1 = layer_0[idx]\n",
    "        image2 = layer_1[idx]\n",
    "        # mu, std = np.mean(layer_2[idx]), np.std(layer_2[idx])\n",
    "        # image3 = (layer_2[idx] - mu) / std\n",
    "        image3 = trans(layer_2[idx])\n",
    "        label = self.labels[idx]\n",
    "        return (image1,image2,image3), label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "d53f48d7",
   "metadata": {
    "id": "d53f48d7"
   },
   "outputs": [],
   "source": [
    "dataset_gamma = CustomImageDataset(np.ones(100000),layer_0,layer_1,layer_2)\n",
    "dataset_ep = CustomImageDataset(np.zeros(100000),layer_0_ep,layer_1_ep,layer_2_ep)\n",
    "total_data = torch.utils.data.ConcatDataset([dataset_gamma, dataset_ep])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "4b9e8653",
   "metadata": {
    "id": "4b9e8653"
   },
   "outputs": [],
   "source": [
    "N = len(total_data)\n",
    "\n",
    "# generate & shuffle indices\n",
    "indices = np.arange(N)\n",
    "indices = np.random.permutation(indices)\n",
    "# there are many ways to do the above two operation. (Example, using np.random.choice can be used here too\n",
    "\n",
    "# select train/test/val, for demo I am using 70,15,15\n",
    "train_indices = indices [:int(0.7*N)]\n",
    "val_indices = indices[int(0.7*N):int(0.85*N)]\n",
    "test_indices = indices[int(0.85*N):]\n",
    "\n",
    "train_dataset = Subset(total_data, train_indices)\n",
    "val_dataset = Subset(total_data, val_indices)\n",
    "test_dataset = Subset(total_data, test_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "8a5eb839-2d0e-40d3-b898-2b51ee217098",
   "metadata": {},
   "outputs": [],
   "source": [
    "global batch_size\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "82f3dcf7",
   "metadata": {
    "id": "82f3dcf7"
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 8, 3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(8, 16, 3, padding=1, stride=2)\n",
    "        self.bn1   = nn.BatchNorm2d(16)\n",
    "        self.conv3 = nn.Conv2d(16, 32, 3, padding=1)\n",
    "        self.conv4 = nn.Conv2d(32, 64, 3, padding=1, stride=2)\n",
    "        self.bn2   = nn.BatchNorm2d(64)\n",
    "        \n",
    "        self.fc1 = nn.Linear(384, 64)\n",
    "        self.fc2 = nn.Linear(64, 1)\n",
    "        \n",
    "\n",
    "    def forward(self, x, y, z):\n",
    "        z = z.reshape(batch_size, 1, 12, 6)\n",
    "        z = F.leaky_relu(self.conv1(z))\n",
    "        z = self.bn1(F.leaky_relu(self.conv2(z)))\n",
    "        # print(z.shape)\n",
    "        z = F.leaky_relu(self.conv3(z))\n",
    "        # print(z.shape)\n",
    "        z = self.bn2(F.leaky_relu(self.conv4(z)))\n",
    "        \n",
    "        z = z.flatten(start_dim=1)\n",
    "        \n",
    "        z = F.leaky_relu(self.fc1(z))\n",
    "        z = F.leaky_relu(self.fc2(z))\n",
    "        return z#F.log_softmax(z, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "63e14053",
   "metadata": {
    "id": "63e14053"
   },
   "outputs": [],
   "source": [
    "heh = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "1ad26512",
   "metadata": {
    "id": "1ad26512"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "6ea6aac2",
   "metadata": {
    "id": "6ea6aac2"
   },
   "outputs": [],
   "source": [
    "dataloaders = {'train':DataLoader(train_dataset, batch_size=batch_size, shuffle=True),\n",
    "               'val':DataLoader(val_dataset, batch_size=batch_size, shuffle=True),\n",
    "               'test':DataLoader(test_dataset, batch_size=batch_size, shuffle=True)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "bfc6c93f",
   "metadata": {
    "id": "bfc6c93f"
   },
   "outputs": [],
   "source": [
    "loss_fn = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "9be14d78",
   "metadata": {
    "id": "9be14d78"
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(heh.parameters(), lr=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "lOeWDhTTIKJv",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lOeWDhTTIKJv",
    "outputId": "29800198-90e6-4805-a23d-17c51db659eb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x2b83927a5d60>"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataloaders['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "2dfb406b",
   "metadata": {
    "id": "2dfb406b"
   },
   "outputs": [],
   "source": [
    "def train_one_epoch(epoch_index):\n",
    "    running_loss = 0.\n",
    "    last_loss = 0.\n",
    "    pbar = tqdm(enumerate(dataloaders['train']))\n",
    "    \n",
    "    for i, (data,labels) in pbar:\n",
    "        \n",
    "        data0,data1,data2 = data\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = heh(data0.float(),data1.float(),data2.float())\n",
    "        \n",
    "        loss = loss_fn(outputs.float().squeeze(), labels.float())\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        if i % 100 == 99:\n",
    "            pbar.set_description('batch {} loss: {}'.format(i + 1, loss))\n",
    "\n",
    "    return last_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "e2e6f82f",
   "metadata": {
    "id": "e2e6f82f"
   },
   "outputs": [],
   "source": [
    "train_loss = []\n",
    "val_loss = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99976592-9e0f-4b7e-a4ea-269a55be8e14",
   "metadata": {},
   "source": [
    "## Basically it ain't training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f82e5a9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 433
    },
    "id": "8f82e5a9",
    "outputId": "7ec761da-0561-45eb-f8cd-204b045e78a0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 1:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch 8700 loss: 0.692940354347229: : 8750it [00:31, 274.58it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS train 0.0 valid 0.6931793689727783\n",
      "EPOCH 2:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch 8700 loss: 0.7041585445404053: : 8750it [02:38, 55.18it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS train 0.0 valid 0.6931775212287903\n",
      "EPOCH 3:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch 8700 loss: 0.6926264762878418: : 8750it [02:07, 68.41it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS train 0.0 valid 0.6931548118591309\n",
      "EPOCH 4:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch 8700 loss: 0.6928288340568542: : 8750it [03:05, 47.07it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS train 0.0 valid 0.6931663155555725\n",
      "EPOCH 5:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch 8700 loss: 0.6933724880218506: : 8750it [00:32, 271.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS train 0.0 valid 0.6931530237197876\n",
      "EPOCH 6:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch 8700 loss: 0.6929121017456055: : 8750it [01:14, 116.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS train 0.0 valid 0.6931483149528503\n",
      "EPOCH 7:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch 8700 loss: 0.6931965947151184: : 8750it [00:32, 268.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS train 0.0 valid 0.6931477189064026\n",
      "EPOCH 8:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch 8700 loss: 0.693550705909729: : 8750it [00:32, 272.19it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS train 0.0 valid 0.6931504011154175\n",
      "EPOCH 9:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch 8700 loss: 0.6942173838615417: : 8750it [00:32, 266.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS train 0.0 valid 0.6931516528129578\n",
      "EPOCH 10:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch 8700 loss: 0.6935548186302185: : 8750it [00:32, 269.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS train 0.0 valid 0.6931540966033936\n",
      "EPOCH 11:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch 8700 loss: 0.6929441690444946: : 8750it [00:32, 266.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS train 0.0 valid 0.6931512355804443\n",
      "EPOCH 12:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch 8700 loss: 0.6935296654701233: : 8750it [00:56, 156.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS train 0.0 valid 0.6931502819061279\n",
      "EPOCH 13:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch 8700 loss: 0.6932529807090759: : 8750it [00:32, 270.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS train 0.0 valid 0.6931516528129578\n",
      "EPOCH 14:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch 8700 loss: 0.693681538105011: : 8750it [00:32, 270.51it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS train 0.0 valid 0.693147599697113\n",
      "EPOCH 15:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch 8700 loss: 0.6931645274162292: : 8750it [00:32, 271.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS train 0.0 valid 0.6931426525115967\n",
      "EPOCH 16:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch 8700 loss: 0.6931378841400146: : 8750it [00:32, 266.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS train 0.0 valid 0.6931535601615906\n",
      "EPOCH 17:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch 8700 loss: 0.6928552985191345: : 8750it [00:37, 234.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS train 0.0 valid 0.6931341290473938\n",
      "EPOCH 18:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch 8700 loss: 0.6846450567245483: : 8750it [01:06, 131.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS train 0.0 valid 0.6931790113449097\n",
      "EPOCH 19:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch 8700 loss: 0.6934871673583984: : 8750it [04:13, 34.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS train 0.0 valid 0.6931484937667847\n",
      "EPOCH 20:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch 1600 loss: 0.6934977769851685: : 1652it [00:48, 34.04it/s]"
     ]
    }
   ],
   "source": [
    "EPOCHS = 30\n",
    "epoch_number = 0\n",
    "\n",
    "best_vloss = 1_00000_000.\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print('EPOCH {}:'.format(epoch_number + 1))\n",
    "\n",
    "    # Make sure gradient tracking is on, and do a pass over the data\n",
    "    heh.train(True)\n",
    "    avg_loss = train_one_epoch(epoch_number)\n",
    "    train_loss.append(avg_loss)\n",
    "    # We don't need gradients on to do reporting\n",
    "    heh.train(False)\n",
    "\n",
    "    running_vloss = 0.0\n",
    "    for i, (vdata,vlabels) in enumerate(dataloaders['val']):\n",
    "        vdata0,vdata1,vdata2 = vdata\n",
    "        voutputs = heh(vdata0.float(),vdata1.float(),vdata2.float())\n",
    "        vloss = loss_fn(voutputs.float().squeeze(), vlabels.float())\n",
    "        running_vloss += vloss\n",
    "\n",
    "    avg_vloss = running_vloss / (i + 1)\n",
    "    val_loss.append(avg_vloss)\n",
    "    print('LOSS train {} valid {}'.format(avg_loss, avg_vloss))\n",
    "\n",
    "    # Log the running loss averaged per batch\n",
    "    # for both training and validation\n",
    "\n",
    "\n",
    "    # Track best performance, and save the model's state\n",
    "#     if avg_vloss < best_vloss:\n",
    "#         best_vloss = avg_vloss\n",
    "#         model_path = 'model_{}_{}'.format(timestamp, epoch_number)\n",
    "#         torch.save(heh.state_dict(), model_path)\n",
    "\n",
    "    epoch_number += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c99660",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 415
    },
    "id": "d8c99660",
    "outputId": "ce94dbd5-af58-473a-f53b-0ca6ba526964"
   },
   "outputs": [],
   "source": [
    "predicts = []\n",
    "real = []\n",
    "for i, (vdata,vlabels) in enumerate(dataloaders['test']):\n",
    "        vdata0,vdata1,vdata2 = vdata\n",
    "        voutputs = heh(vdata0.float(),vdata1.float(),vdata2.float())\n",
    "        vloss = loss_fn(voutputs.squeeze(), vlabels)\n",
    "        pred = voutputs > 0.5\n",
    "        pred = 1 * pred\n",
    "        running_vloss += vloss\n",
    "        for i in pred:\n",
    "            predicts.append(i.item())\n",
    "        for i in vlabels:\n",
    "            real.append(i.item())\n",
    "\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "502489d8",
   "metadata": {
    "id": "502489d8",
    "outputId": "1418dca9-4063-43f5-c5f9-d78319d8a020"
   },
   "outputs": [],
   "source": [
    "print(accuracy_score(real,predicts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "0b44b784",
   "metadata": {
    "id": "0b44b784"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "83335f3b",
   "metadata": {
    "id": "83335f3b",
    "outputId": "c1e1984a-a935-4edb-dd87-b655bf8c78f6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2b840b8ef6d0>]"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_loss)\n",
    "plt.plot([i.item() for i in val_loss])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef2e9bb",
   "metadata": {
    "id": "9ef2e9bb"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612a9af2",
   "metadata": {
    "id": "612a9af2"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python [.conda-env_gpu]",
   "language": "python",
   "name": "conda-env-.conda-env_gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
